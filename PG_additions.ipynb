{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d79f9edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import csv\n",
    "import os\n",
    "import sys \n",
    "import time\n",
    "assert os.environ.get('DB_PASS') != None , 'empty password!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c2ac679",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"dbname='amtrakproject' user='{}' password={}\".format(os.environ.get('USER'), os.environ.get('DB_PASS')))\n",
    "assert conn is not None, 'need to fix conn!!'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0420ec",
   "metadata": {},
   "source": [
    "### Table_names for reference:\n",
    "* `station_info`\n",
    "* `all_trains`\n",
    "* `weather_hourly`\n",
    "* `regional_route`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31d46341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_command(conn, command):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(command)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb99f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c055381",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql postgresql://elizabethchen:test@localhost:5432/amtrakproject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aa0ba7",
   "metadata": {},
   "source": [
    "### See how many unique values there are for `act_arr_dep_time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be63295b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://elizabethchen:***@localhost:5432/amtrakproject\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1440</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1440,)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT \n",
    "    COUNT(DISTINCT act_arr_dep_time)\n",
    "FROM \n",
    "    all_trains;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3263ae7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://elizabethchen:***@localhost:5432/amtrakproject\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1394064</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1394064,)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT \n",
    "    COUNT(act_arr_dep_time)\n",
    "FROM \n",
    "    all_trains;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a25501",
   "metadata": {},
   "source": [
    "### Create index on `act_arr_dep_time` for trains table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3199976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_arr_dep_index = \"\"\"\n",
    "                       CREATE INDEX act_time ON all_trains (act_arr_dep_time);\n",
    "                       \"\"\"\n",
    "# ALREADY RAN execute_command(conn, create_arr_dep_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785da5ac",
   "metadata": {},
   "source": [
    "### ADD COLUMNS TO `all_trains`: weather hourly round up/down weights\n",
    "* Weights are determined by the following formulas, where `num_mins` is the extracted minutes part of the actual arrival/departure time at a given station\n",
    "    * `round_up_weight` (round up to nearest hour): $$\\frac{\\texttt{num_mins}}{60}$$\n",
    "    * `round_down_weight` (round down to nearest hour): $$\\frac{60 - \\texttt{num_mins}}{60}$$\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31e43f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_weights_and_round_hours = \"\"\"\n",
    "                              ALTER TABLE all_trains\n",
    "                              ADD COLUMN round_down_weight real,\n",
    "                              ADD COLUMN round_up_weight real,\n",
    "                              ADD COLUMN full_act_datetime_round_down timestamp,\n",
    "                              ADD COLUMN full_act_datetime_round_up timestamp;\n",
    "                              \"\"\"\n",
    "\n",
    "# ALREADY RAN execute_command(conn, add_weights_and_round_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d88f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_weights_and_round_hours_part1 = \"\"\"\n",
    "                                    UPDATE all_trains \n",
    "                                    SET round_up_weight = subquery.up_weight,\n",
    "                                        full_act_datetime_round_down = subquery.trunc_hour\n",
    "                                    FROM (\n",
    "                                       SELECT\n",
    "                                           t.dataset_id AS dataset_id,\n",
    "                                           EXTRACT (MINUTES FROM t.full_act_arr_dep_datetime)/60 AS up_weight,\n",
    "                                           DATE_TRUNC('hour', t.full_act_arr_dep_datetime) AS trunc_hour\n",
    "                                        FROM all_trains t\n",
    "                                   ) AS subquery\n",
    "                                   WHERE all_trains.dataset_id = subquery.dataset_id;\n",
    "                               \"\"\"\n",
    "# ALREADY RAN execute_command(conn, set_weights_and_round_hours_part1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c13afe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_weights_and_round_hours_part2 = \"\"\"\n",
    "                                    UPDATE all_trains \n",
    "                                    SET round_down_weight = subquery.down_weight,\n",
    "                                        full_act_datetime_round_up = subquery.round_up_hour\n",
    "                                    FROM (\n",
    "                                       SELECT\n",
    "                                           t.dataset_id AS dataset_id,\n",
    "                                           1 - t.round_up_weight AS down_weight,\n",
    "                                           t.full_act_datetime_round_down +  INTERVAL '1 hour' AS round_up_hour\n",
    "                                        FROM all_trains t\n",
    "                                   ) AS subquery\n",
    "                                   WHERE all_trains.dataset_id = subquery.dataset_id;\n",
    "                                   \"\"\"\n",
    "\n",
    "# ALREADY RAN execute_command(conn, set_weights_and_round_hours_part2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce76661",
   "metadata": {},
   "source": [
    "### Test out the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e2fa6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://elizabethchen:***@localhost:5432/amtrakproject\n",
      "15 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>act_arr_dep_time</th>\n",
       "        <th>round_down_weight</th>\n",
       "        <th>round_up_weight</th>\n",
       "        <th>full_act_datetime_round_down</th>\n",
       "        <th>full_act_datetime_round_up</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>22:42:00</td>\n",
       "        <td>0.3</td>\n",
       "        <td>0.7</td>\n",
       "        <td>2012-02-05 22:00:00</td>\n",
       "        <td>2012-02-05 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>11:09:00</td>\n",
       "        <td>0.85</td>\n",
       "        <td>0.15</td>\n",
       "        <td>2012-03-21 11:00:00</td>\n",
       "        <td>2012-03-21 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>19:03:00</td>\n",
       "        <td>0.95</td>\n",
       "        <td>0.05</td>\n",
       "        <td>2012-03-21 19:00:00</td>\n",
       "        <td>2012-03-21 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>19:05:00</td>\n",
       "        <td>0.9166667</td>\n",
       "        <td>0.083333336</td>\n",
       "        <td>2012-03-23 19:00:00</td>\n",
       "        <td>2012-03-23 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>03:37:00</td>\n",
       "        <td>0.38333333</td>\n",
       "        <td>0.6166667</td>\n",
       "        <td>2012-03-24 03:00:00</td>\n",
       "        <td>2012-03-24 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>19:04:00</td>\n",
       "        <td>0.93333334</td>\n",
       "        <td>0.06666667</td>\n",
       "        <td>2012-04-02 19:00:00</td>\n",
       "        <td>2012-04-02 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>19:01:00</td>\n",
       "        <td>0.98333335</td>\n",
       "        <td>0.016666668</td>\n",
       "        <td>2012-04-12 19:00:00</td>\n",
       "        <td>2012-04-12 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>14:39:00</td>\n",
       "        <td>0.35000002</td>\n",
       "        <td>0.65</td>\n",
       "        <td>2012-04-16 14:00:00</td>\n",
       "        <td>2012-04-16 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>19:10:00</td>\n",
       "        <td>0.8333333</td>\n",
       "        <td>0.16666667</td>\n",
       "        <td>2012-04-17 19:00:00</td>\n",
       "        <td>2012-04-17 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>19:03:00</td>\n",
       "        <td>0.95</td>\n",
       "        <td>0.05</td>\n",
       "        <td>2012-04-24 19:00:00</td>\n",
       "        <td>2012-04-24 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>19:04:00</td>\n",
       "        <td>0.93333334</td>\n",
       "        <td>0.06666667</td>\n",
       "        <td>2012-04-30 19:00:00</td>\n",
       "        <td>2012-04-30 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>03:37:00</td>\n",
       "        <td>0.38333333</td>\n",
       "        <td>0.6166667</td>\n",
       "        <td>2012-05-02 03:00:00</td>\n",
       "        <td>2012-05-02 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>11:20:00</td>\n",
       "        <td>0.6666666</td>\n",
       "        <td>0.33333334</td>\n",
       "        <td>2012-05-08 11:00:00</td>\n",
       "        <td>2012-05-08 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>14:38:00</td>\n",
       "        <td>0.36666667</td>\n",
       "        <td>0.6333333</td>\n",
       "        <td>2012-05-08 14:00:00</td>\n",
       "        <td>2012-05-08 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>19:03:00</td>\n",
       "        <td>0.95</td>\n",
       "        <td>0.05</td>\n",
       "        <td>2012-05-24 19:00:00</td>\n",
       "        <td>2012-05-24 20:00:00</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(datetime.time(22, 42), 0.3, 0.7, datetime.datetime(2012, 2, 5, 22, 0), datetime.datetime(2012, 2, 5, 23, 0)),\n",
       " (datetime.time(11, 9), 0.85, 0.15, datetime.datetime(2012, 3, 21, 11, 0), datetime.datetime(2012, 3, 21, 12, 0)),\n",
       " (datetime.time(19, 3), 0.95, 0.05, datetime.datetime(2012, 3, 21, 19, 0), datetime.datetime(2012, 3, 21, 20, 0)),\n",
       " (datetime.time(19, 5), 0.9166667, 0.083333336, datetime.datetime(2012, 3, 23, 19, 0), datetime.datetime(2012, 3, 23, 20, 0)),\n",
       " (datetime.time(3, 37), 0.38333333, 0.6166667, datetime.datetime(2012, 3, 24, 3, 0), datetime.datetime(2012, 3, 24, 4, 0)),\n",
       " (datetime.time(19, 4), 0.93333334, 0.06666667, datetime.datetime(2012, 4, 2, 19, 0), datetime.datetime(2012, 4, 2, 20, 0)),\n",
       " (datetime.time(19, 1), 0.98333335, 0.016666668, datetime.datetime(2012, 4, 12, 19, 0), datetime.datetime(2012, 4, 12, 20, 0)),\n",
       " (datetime.time(14, 39), 0.35000002, 0.65, datetime.datetime(2012, 4, 16, 14, 0), datetime.datetime(2012, 4, 16, 15, 0)),\n",
       " (datetime.time(19, 10), 0.8333333, 0.16666667, datetime.datetime(2012, 4, 17, 19, 0), datetime.datetime(2012, 4, 17, 20, 0)),\n",
       " (datetime.time(19, 3), 0.95, 0.05, datetime.datetime(2012, 4, 24, 19, 0), datetime.datetime(2012, 4, 24, 20, 0)),\n",
       " (datetime.time(19, 4), 0.93333334, 0.06666667, datetime.datetime(2012, 4, 30, 19, 0), datetime.datetime(2012, 4, 30, 20, 0)),\n",
       " (datetime.time(3, 37), 0.38333333, 0.6166667, datetime.datetime(2012, 5, 2, 3, 0), datetime.datetime(2012, 5, 2, 4, 0)),\n",
       " (datetime.time(11, 20), 0.6666666, 0.33333334, datetime.datetime(2012, 5, 8, 11, 0), datetime.datetime(2012, 5, 8, 12, 0)),\n",
       " (datetime.time(14, 38), 0.36666667, 0.6333333, datetime.datetime(2012, 5, 8, 14, 0), datetime.datetime(2012, 5, 8, 15, 0)),\n",
       " (datetime.time(19, 3), 0.95, 0.05, datetime.datetime(2012, 5, 24, 19, 0), datetime.datetime(2012, 5, 24, 20, 0))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT  \n",
    "    act_arr_dep_time,\n",
    "    round_down_weight,\n",
    "    round_up_weight,\n",
    "    full_act_datetime_round_down,\n",
    "    full_act_datetime_round_up \n",
    "FROM \n",
    "    all_trains \n",
    "LIMIT 15;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f88fb34",
   "metadata": {},
   "source": [
    "### Create index on `date_time` for weather table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0ca6a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dt_index_weather = \"\"\"\n",
    "                          CREATE INDEX dt_index ON weather_hourly (date_time);\n",
    "                          \"\"\"\n",
    "# ALREADY RAN execute_command(conn, create_dt_index_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb33675",
   "metadata": {},
   "source": [
    "### View the weather columns and data types we will need to join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "221685b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://elizabethchen:***@localhost:5432/amtrakproject\n",
      "10 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>column_name</th>\n",
       "        <th>data_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>weather_id</td>\n",
       "        <td>integer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>location</td>\n",
       "        <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>date_time</td>\n",
       "        <td>timestamp without time zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>temperature</td>\n",
       "        <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>precipitation</td>\n",
       "        <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>cloud_cover</td>\n",
       "        <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>conditions</td>\n",
       "        <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>weather_type</td>\n",
       "        <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>latitude</td>\n",
       "        <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>longitude</td>\n",
       "        <td>real</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('weather_id', 'integer'),\n",
       " ('location', 'text'),\n",
       " ('date_time', 'timestamp without time zone'),\n",
       " ('temperature', 'real'),\n",
       " ('precipitation', 'real'),\n",
       " ('cloud_cover', 'real'),\n",
       " ('conditions', 'text'),\n",
       " ('weather_type', 'text'),\n",
       " ('latitude', 'real'),\n",
       " ('longitude', 'real')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT \n",
    "    column_name,\n",
    "    data_type\n",
    "FROM \n",
    "    information_schema.columns\n",
    "WHERE\n",
    "    table_name = 'weather_hourly';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08311ce5",
   "metadata": {},
   "source": [
    "### Plan for joining/merging weighted average weather for train data:\n",
    "* `temperature`, `precipitation`, `cloud_cover` are all numeric values and can easily be averaged using the `up` and `down` weights previously calculated for the trains table\n",
    "* `conditions` is 99%+ not null,  `weather_type` is mostly null but gives additional information when it is not null\n",
    "    * `DISTINCT VALUES`: `Partially cloudy`, `Overcast`, `Rain, Partially cloudy`, `Rain, Overcast`, `Rain`, `Clear`\n",
    "    * (`Snow` is included/mentioned in the `weather_type` column)\n",
    "    * Test #1: take set intersection of previous and next hour `conditions`\n",
    "        * If no results in some places, continue to next Test\n",
    "    * Test #2: take set union of previous and next hour `conditions`, order by the assigned `weight`\n",
    "        * Options for combining/summarizing:\n",
    "            * Reduce the quantity of observation types by converting very specific weather types to more general ones\n",
    "                * E.g. \"Freezing Drizzle/Freezing Rain\" could be converted to a \"Rain\" column on some sort of scale TBD (Ex: `1 = \"Mist\", 2 = \"Drizzle\", ... , K = \"Heavy Freezing Rain\", ..., Z = \"Hail\"`)\n",
    "            * If two variations of the same precipitation or condition type, e.g. \"Heavy Rain\" and \"Freezing Drizzle/Freezing Rain\" appear in the same entry, take the one with the higher weight and add associated precipitation value to precip_marker column\n",
    "            \n",
    "### Idea: Assign numeric scale to all distinct values attributes, then average the numeric valued combinations of attributes over the set and use this numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c569344d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
