{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d79f9edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import csv\n",
    "import os\n",
    "import sys \n",
    "import time\n",
    "import pandas as pd\n",
    "assert os.environ.get('DB_PASS') != None , 'empty password!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c2ac679",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"dbname='amtrakproject' user='{}' password={}\".format(os.environ.get('USER'), os.environ.get('DB_PASS')))\n",
    "assert conn is not None, 'need to fix conn!!'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0420ec",
   "metadata": {},
   "source": [
    "### Table_names for reference:\n",
    "* `station_info`\n",
    "* `stops`\n",
    "* `weather_hourly`\n",
    "* `regional_route`\n",
    "* to create: `trips`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31d46341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_command(conn, command):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(command)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb99f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c055381",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql postgresql://elizabethchen:test@localhost:5432/amtrakproject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aa0ba7",
   "metadata": {},
   "source": [
    "### See how many unique values there are for `act_arr_dep_time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be63295b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://elizabethchen:***@localhost:5432/amtrakproject\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>1440</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(1440,)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "\n",
    "SELECT \n",
    "    COUNT(DISTINCT act_arr_dep_time)\n",
    "FROM \n",
    "    stops;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f957cf",
   "metadata": {},
   "source": [
    "### Create track sharing column\n",
    "* Count of number of other railroads sharing the tracks between stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b2fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_query = \"\"\"\n",
    "              SELECT \n",
    "                  CASE \n",
    "                      WHEN station_code IN ('KIN', 'WLY', 'MYS') THEN 0\n",
    "                      WHEN station_code in ('NHV', 'BRP', 'STM', 'NRO') THEN 2\n",
    "                      ELSE 1\n",
    "                  END Num_Other_RR_On_Tracks\n",
    "              FROM \n",
    "                  all_trains;\n",
    "              \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_shared_tracks = \"\"\"\n",
    "                    ALTER TABLE all_trains\n",
    "                    ADD COLUMN Num_Other_RR_Sharing integer;\n",
    "                    UPDATE stops\n",
    "                    SET Num_Other_RR_Sharing = (\n",
    "                                      SELECT \n",
    "                                          CASE \n",
    "                                              WHEN station_code IN ('KIN', 'WLY', 'MYS') THEN 0\n",
    "                                              WHEN station_code in ('NHV', 'BRP', 'STM', 'NRO') THEN 2\n",
    "                                              ELSE 1\n",
    "                                          END Num_Other_RR_On_Tracks\n",
    "                                      FROM \n",
    "                                          stops;\n",
    "                    );\n",
    "                    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f88fb34",
   "metadata": {},
   "source": [
    "### Create index on `date_time` for weather table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ca6a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dt_index_weather = \"\"\"\n",
    "                          CREATE INDEX dt_index ON weather_hourly (date_time);\n",
    "                          \"\"\"\n",
    "# ALREADY RAN execute_command(conn, create_dt_index_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb33675",
   "metadata": {},
   "source": [
    "### View the weather columns and data types we will need to join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221685b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "SELECT \n",
    "    column_name,\n",
    "    data_type\n",
    "FROM \n",
    "    information_schema.columns\n",
    "WHERE\n",
    "    table_name = 'weather_hourly';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08311ce5",
   "metadata": {},
   "source": [
    "### Plan for joining/merging weighted average weather for train data:\n",
    "* `temperature`, `precipitation`, `cloud_cover` are all numeric values and can easily be averaged using the `up` and `down` weights previously calculated for the trains table\n",
    "* `conditions` is 99%+ not null,  `weather_type` is mostly null but gives additional information when it is not null\n",
    "    * `DISTINCT VALUES`: `Partially cloudy`, `Overcast`, `Rain, Partially cloudy`, `Rain, Overcast`, `Rain`, `Clear`\n",
    "    * (`Snow` is included/mentioned in the `weather_type` column)\n",
    "    * Test #1: take set intersection of previous and next hour `conditions`\n",
    "        * If no results in some places, continue to next Test\n",
    "    * Test #2: take set union of previous and next hour `conditions`, order by the assigned `weight`\n",
    "        * Options for combining/summarizing:\n",
    "            * Reduce the quantity of observation types by converting very specific weather types to more general ones\n",
    "                * E.g. \"Freezing Drizzle/Freezing Rain\" could be converted to a \"Rain\" column on some sort of scale TBD (Ex: `1 = \"Mist\", 2 = \"Drizzle\", ... , K = \"Heavy Freezing Rain\", ..., Z = \"Hail\"`)\n",
    "            * If two variations of the same precipitation or condition type, e.g. \"Heavy Rain\" and \"Freezing Drizzle/Freezing Rain\" appear in the same entry, take the one with the higher weight and add associated precipitation value to precip_marker column\n",
    "            \n",
    "### Idea: Assign numeric scale to all distinct values attributes, then average the numeric valued combinations of attributes over the set and use this numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c569344d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d95daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_explainA = \"\"\"\n",
    "                BEGIN;\n",
    "                EXPLAIN ANALYZE UPDATE all_trains \n",
    "                SET round_up_weight = subquery.up_weight,\n",
    "                    full_act_datetime_round_down = subquery.trunc_hour\n",
    "                FROM (\n",
    "                   SELECT\n",
    "                       t.dataset_id AS dataset_id,\n",
    "                       EXTRACT (MINUTES FROM t.full_act_arr_dep_datetime)/60 AS up_weight,\n",
    "                       DATE_TRUNC('hour', t.full_act_arr_dep_datetime) AS trunc_hour\n",
    "                    FROM all_trains t\n",
    "               ) AS subquery\n",
    "               WHERE all_trains.dataset_id = subquery.dataset_id;\n",
    "               ROLLBACK;\n",
    "               \"\"\"\n",
    "\n",
    "# ALREADY RAN execute_command(conn, set_weights_and_round_hours_part1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2a92cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_and_get_results(conn, command):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(command)\n",
    "        return cur.fetchall()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e64304",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "        SELECT\n",
    "            train_num, \n",
    "            arr_or_dep,\n",
    "            t.station_code,\n",
    "            full_sched_arr_dep_datetime,\n",
    "            full_act_arr_dep_datetime,\n",
    "            timedelta_from_sched,\n",
    "            temperature, \n",
    "            date_time,\n",
    "            precipitation, \n",
    "            cloud_cover, \n",
    "            conditions, \n",
    "            weather_type, \n",
    "            crew_change, \n",
    "            sb_mile\n",
    "        FROM\n",
    "            all_trains t\n",
    "        INNER JOIN (\n",
    "            SELECT\n",
    "                si.station_code,\n",
    "                location,\n",
    "                date_time,\n",
    "                temperature, \n",
    "                precipitation, \n",
    "                cloud_cover, \n",
    "                conditions, \n",
    "                weather_type, \n",
    "                crew_change, \n",
    "                sb_mile\n",
    "            FROM \n",
    "                weather_hourly\n",
    "            INNER JOIN (\n",
    "                SELECT\n",
    "                    weather_station,\n",
    "                    station_code,\n",
    "                    crew_change,\n",
    "                    sb_mile\n",
    "                FROM\n",
    "                    station_info\n",
    "            ) AS si  \n",
    "            ON location = si.weather_station\n",
    "            WHERE DATE_TRUNC('day', date_time) = '2021-04-25'\n",
    "        ) AS wh\n",
    "        ON t.station_code = wh.station_code\n",
    "        WHERE\n",
    "            DATE_TRUNC('hour', full_act_arr_dep_datetime) = wh.date_time\n",
    "        AND \n",
    "            train_num = '135'\n",
    "        ORDER BY\n",
    "            full_act_arr_dep_datetime\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa38f3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ead3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed62eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('~/Desktop/results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fdde3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5076a6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
