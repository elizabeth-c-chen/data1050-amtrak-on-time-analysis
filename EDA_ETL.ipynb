{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7b64903",
   "metadata": {},
   "source": [
    "# ETL and EDA Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1bd0e4",
   "metadata": {},
   "source": [
    "# Part 1 - Amtrak Northeast Regional Train Data\n",
    "* This project would not be possible without the diligent joint effort by [Chris Juckins](https://juckins.net/index.php) and [John Bobinyec](http://dixielandsoftware.net/Amtrak/status/StatusMaps/) to collect and preserve Amtrak's on-time performance records. Chris Juckins' archive of timetables was another invaluable resource which enabled me to sort through the trains and stations I chose to use in this project.\n",
    "* The train data is sourced from [Amtrak Status Maps Archive Database (ASMAD)](https://juckins.net/amtrak_status/archive/html/home.php), and has been retrieved with Chris' permission.\n",
    "\n",
    "### Overview of the Process\n",
    "* Functions were written to scrape the HTML table returned from the search query and to process each column to the desired format\n",
    "* Additional columns were also added during processing to aid in joining the train data with weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770400b6",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd7938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import re\n",
    "import lxml.html as lh\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta\n",
    "from trains_retrieve_and_process_data import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bee1b4",
   "metadata": {},
   "source": [
    "### Retrieve HTML table data and recreate as a Pandas DataFrame\n",
    "* Default is to collect data from the previous day (run after 5am or else no data will be retrieved, ASMAD updates around 4am)\n",
    "* Collects both arrival and departure data and stores in a dictionary further indexed by station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca05328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = date(2021,6,11)\n",
    "end = date(2021,6,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864d7421",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = retrieve_data(start=start, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd909dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "depart =  raw_data_to_raw_df(raw_data, 'Depart')\n",
    "print(depart.shape[0])\n",
    "depart.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a6c5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrive = raw_data_to_raw_df(raw_data, 'Arrive')\n",
    "print(arrive.shape[0])\n",
    "arrive.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35503c7",
   "metadata": {},
   "source": [
    "### Save the raw DF to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a25110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrive_filestring = './data/trains_raw/arrive_raw_{}_{}.csv'.format(str(start), str(end))\n",
    "depart_filestring = './data/trains_raw/depart_raw_{}_{}.csv'.format(str(start), str(end))\n",
    "\n",
    "arrive.to_csv(arrive_filestring, line_terminator='\\n', index=False)\n",
    "depart.to_csv(depart_filestring, line_terminator='\\n', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dd1957",
   "metadata": {},
   "source": [
    "### Process the raw DF with modifications/additions \n",
    "* Modifications to the data:\n",
    "    * Separate the Origin Date and Origin Week Day  into two columns\n",
    "    * Add separate columns for Origin Year and Origin Month\n",
    "    * Separate the Scheduled Arrival/Departure Date, Scheduled Arrival/Departure Week Day, and Scheduled Arrival/Departure Time into three seperate columns\n",
    "    * Calculate the value of the time difference between Scheduled and Actual Arrival/Departure\n",
    "    * Convert Service Disruption and Cancellation column text flags to binary indicator columns\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff1108",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_arrive = process_columns(arrive, 'Arrive')\n",
    "full_arrive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d460314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_depart = process_columns(depart, \"Depart\")\n",
    "full_depart.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57a9f09",
   "metadata": {},
   "source": [
    "### For new 2021 data, concatenate with previously retrieved and processed data from this year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b52e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrive_filestring2021 = './data/trains/arrive_2021_processed.csv'\n",
    "depart_filestring2021 = './data/trains/depart_2021_processed.csv'\n",
    "        \n",
    "prev_arrive2021 = pd.read_csv(arrive_filestring2021)\n",
    "prev_depart2021 = pd.read_csv(depart_filestring2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a47fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arrive2021 = pd.concat([prev_arrive2021, full_arrive], ignore_index=True, axis=0)\n",
    "new_depart2021 = pd.concat([prev_depart2021, full_depart], ignore_index=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafbd636",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arrive2021.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15f1c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_depart2021.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf8436b",
   "metadata": {},
   "source": [
    "### Drop duplicate rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4c061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arrive2021.drop_duplicates(inplace = True, ignore_index = True)\n",
    "new_arrive2021.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95aee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_depart2021.drop_duplicates(inplace = True, ignore_index = True)\n",
    "new_depart2021.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arrive2021.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90aae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arrive2021.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a231e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_depart2021.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5df6808",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_depart2021.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6775ec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arrive2021.to_csv(arrive_filestring2021, line_terminator='\\n', index=False)\n",
    "new_depart2021.to_csv(depart_filestring2021, line_terminator='\\n', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdecb55",
   "metadata": {},
   "source": [
    "# Part 2 - Visual Crossing Weather Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe05c71",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f27186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a70afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weather_retrieve_and_process_data import *\n",
    "assert os.environ.get('VC_TOKEN') is not None , 'empty token!'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068b6ac",
   "metadata": {},
   "source": [
    "### Retrieve unprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3831a5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = str(date(2021,6,10))\n",
    "end = str(date.today()-timedelta(days=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc081561",
   "metadata": {},
   "outputs": [],
   "source": [
    "successful_retrievals = retrieve_weather_data(start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c36c337",
   "metadata": {},
   "source": [
    "### Data Cleaning/Taking Subset of Columns\n",
    "\n",
    "* Processing recent data by year - add new columns, make minor fixes to string format, take subset of full columns list.\n",
    "* Function processes the files that were successfully created in the previous step.\n",
    "* This part is assuming 2021 data is being read and concatenates the previously retrieved data with the new data to create a single combined file.\n",
    "* Output shows the fraction of the data kept, data is valid and complete almost always ($> 99\\%$ of original data has been retained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4ef7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_weather_data(successful_retrievals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f95a2c",
   "metadata": {},
   "source": [
    "### Data sample for viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4286faeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('./data/weather/Providence_RI_weather_subset_2021.csv')\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8693d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9be4bd",
   "metadata": {},
   "source": [
    "# Part 3a: Loading Data into Postgres Database\n",
    "Schema pictured below:\n",
    "![Database Schema](data/schema/Final_DB_Schema.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca8a15",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c5aeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import csv\n",
    "import os\n",
    "import sys \n",
    "import time\n",
    "assert os.environ.get('DB_PASS') != None , 'empty password!'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb8e2da",
   "metadata": {},
   "source": [
    "#### Functions to create and update tables in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f6d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_command(conn, command):\n",
    "    \"\"\"\n",
    "    Execute specified command in PostgreSQL database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(command)\n",
    "        conn.commit()\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        conn.rollback()\n",
    "\n",
    "def update_table(conn, command, csv_file):\n",
    "    \"\"\"\n",
    "    Insert rows from a CSV file into table specified by the command.\n",
    "    \"\"\"\n",
    "    cur = conn.cursor()\n",
    "    with open(csv_file, newline='') as file:\n",
    "        info_reader = csv.reader(file, delimiter=',')\n",
    "        next(info_reader) # Skip header                                                                          \n",
    "        for row in info_reader:                                           \n",
    "            try:\n",
    "                cur.execute(command, tuple(row))\n",
    "            except (Exception, psycopg2.DatabaseError) as error:\n",
    "                print(error)\n",
    "                conn.rollback()\n",
    "        conn.commit() \n",
    "        \n",
    "def update_trains(conn, command, arr_or_dep, csv_file):\n",
    "    \"\"\"\n",
    "    Insert rows from trains CSV file into table specified by the command.\n",
    "    \"\"\"\n",
    "    cur = conn.cursor()\n",
    "    with open(csv_file, newline='') as file:\n",
    "        info_reader = csv.reader(file, delimiter=',')\n",
    "        next(info_reader) # Skip header                                                                          \n",
    "        for row in info_reader:                                           \n",
    "            try:\n",
    "                cur.execute(command, tuple([arr_or_dep] + row))\n",
    "            except (Exception, psycopg2.DatabaseError) as error:\n",
    "                print(error)\n",
    "                conn.rollback()\n",
    "        conn.commit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99334dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"dbname='amtrakproject' user='{}' password={}\".format(os.environ.get('USER'), os.environ.get('DB_PASS')))\n",
    "assert conn is not None, 'need to fix conn!!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a31e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_station_info = \"\"\" \n",
    "                      DROP TABLE IF EXISTS station_info CASCADE;\n",
    "                      CREATE TABLE station_info (\n",
    "                          station_code text UNIQUE PRIMARY KEY,\n",
    "                          amtrak_station_name text,\n",
    "                          crew_change boolean,\n",
    "                          weather_location_name text,\n",
    "                          longitude real,\n",
    "                          latitude real,\n",
    "                          nb_next_station text,\n",
    "                          sb_next_station text,\n",
    "                          nb_mile numeric,\n",
    "                          sb_mile numeric,\n",
    "                          nb_stop_num numeric,\n",
    "                          sb_stop_num numeric,\n",
    "                          nb_miles_to_next numeric,\n",
    "                          sb_miles_to_next numeric\n",
    "                      );\n",
    "                      \"\"\"\n",
    "\n",
    "insert_into_station_info = \"\"\"\n",
    "                           INSERT INTO\n",
    "                               station_info (\n",
    "                                   station_code,\n",
    "                                   amtrak_station_name,\n",
    "                                   crew_change,\n",
    "                                   weather_location_name,\n",
    "                                   longitude,\n",
    "                                   latitude,\n",
    "                                   nb_next_station,\n",
    "                                   sb_next_station,\n",
    "                                   nb_mile,\n",
    "                                   sb_mile,\n",
    "                                   nb_stop_num,\n",
    "                                   sb_stop_num,\n",
    "                                   nb_miles_to_next,\n",
    "                                   sb_miles_to_next\n",
    "\n",
    "                             )\n",
    "                         VALUES\n",
    "                             (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                         ON CONFLICT DO NOTHING;\n",
    "                         \"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b1b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stops = \"\"\"\n",
    "                 DROP TABLE IF EXISTS stops CASCADE;\n",
    "                 CREATE TABLE stops (\n",
    "                     stop_id SERIAL PRIMARY KEY,\n",
    "                     arrival_or_departure text, \n",
    "                     train_num text,\n",
    "                     station_code text REFERENCES station_info,\n",
    "                     direction text,\n",
    "                     origin_date date,\n",
    "                     origin_year int,\n",
    "                     origin_month int,\n",
    "                     origin_week_day text,\n",
    "                     full_sched_arr_dep_datetime timestamp,\n",
    "                     sched_arr_dep_date date,\n",
    "                     sched_arr_dep_week_day text,\n",
    "                     sched_arr_dep_time time,\n",
    "                     act_arr_dep_time time,\n",
    "                     full_act_arr_dep_datetime timestamp,\n",
    "                     timedelta_from_sched numeric,\n",
    "                     service_disruption boolean,\n",
    "                     cancellations boolean\n",
    "                 );\n",
    "               \"\"\"\n",
    "\n",
    "insert_into_stops = \"\"\"\n",
    "                    INSERT INTO\n",
    "                        stops (\n",
    "                            arrival_or_departure,\n",
    "                            train_num,\n",
    "                            station_code,\n",
    "                            direction,\n",
    "                            origin_date,\n",
    "                            origin_year,\n",
    "                            origin_month,\n",
    "                            origin_week_day,\n",
    "                            full_sched_arr_dep_datetime,\n",
    "                            sched_arr_dep_date,\n",
    "                            sched_arr_dep_week_day,\n",
    "                            sched_arr_dep_time,\n",
    "                            act_arr_dep_time,\n",
    "                            full_act_arr_dep_datetime,\n",
    "                            timedelta_from_sched,\n",
    "                            service_disruption,\n",
    "                            cancellations\n",
    "                          )\n",
    "                      VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                      ON CONFLICT DO NOTHING;\n",
    "                      \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f346bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_weather = \"\"\"\n",
    "                 DROP TABLE IF EXISTS weather_hourly CASCADE;\n",
    "                 CREATE TABLE weather_hourly (\n",
    "                     weather_id SERIAL PRIMARY KEY,\n",
    "                     location text,\n",
    "                     obs_datetime timestamp,\n",
    "                     temperature real,\n",
    "                     precipitation real,\n",
    "                     cloud_cover real,\n",
    "                     weather_type text\n",
    "                 );\n",
    "                 \"\"\"\n",
    "\n",
    "insert_into_weather = \"\"\"\n",
    "                      INSERT INTO\n",
    "                          weather_hourly (\n",
    "                              location,\n",
    "                              obs_datetime,\n",
    "                              temperature,\n",
    "                              precipitation,\n",
    "                              cloud_cover,\n",
    "                              weather_type\n",
    "                      )\n",
    "                      VALUES\n",
    "                          (%s, %s, %s, %s, %s, %s) \n",
    "                      ON CONFLICT DO NOTHING;\n",
    "                      \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25ac833",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_route = \"\"\"\n",
    "               DROP TABLE IF EXISTS regional_route CASCADE;\n",
    "\n",
    "               CREATE TABLE regional_route (\n",
    "                 coord_id SERIAL PRIMARY KEY,\n",
    "                 longitude real,\n",
    "                 latitude real,\n",
    "                 path_group numeric,\n",
    "                 connecting_path text, \n",
    "                 nb_station_group text,\n",
    "                 sb_station_group text\n",
    "               );\n",
    "               \"\"\"\n",
    "\n",
    "insert_into_route = \"\"\"\n",
    "                    INSERT INTO\n",
    "                      regional_route (\n",
    "                          longitude,\n",
    "                          latitude, \n",
    "                          path_group,\n",
    "                          connecting_path,\n",
    "                          nb_station_group,\n",
    "                          sb_station_group\n",
    "                      )\n",
    "                    VALUES \n",
    "                        (%s, %s, %s, %s, %s, %s) \n",
    "                    ON CONFLICT DO NOTHING;\n",
    "                    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7737b1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"dbname='amtrakproject' user={} password={}\".format(os.environ.get('USER'), os.environ.get('DB_PASS')))\n",
    "assert conn is not None, 'need to fix conn!!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8e0269",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_cmds = [create_station_info, create_stops, create_weather,  create_route]\n",
    "\n",
    "for cmd in create_table_cmds:\n",
    "    execute_command(conn, cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf62f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert all station facts into station info table\n",
    "update_table(conn, insert_into_station_info, './data/facts/geo_stations_info.csv')\n",
    "\n",
    "# Insert route with the coordiniates into route table\n",
    "update_table(conn, insert_into_route, './data/facts/NE_regional_lonlat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2b5a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]\n",
    "\n",
    "begin_everything = time.time()\n",
    "\n",
    "# Insert all train data into arrival and departure data tables\n",
    "for year in years:\n",
    "    start = time.time()\n",
    "    arrive_csv = './data/trains/arrive_{}_processed.csv'.format(year)\n",
    "    depart_csv = './data/trains/depart_{}_processed.csv'.format(year)\n",
    "    update_trains(conn, insert_into_stops, 'Arrival', arrive_csv)\n",
    "    update_trains(conn, insert_into_stops, 'Departure', depart_csv)\n",
    "    print('Finished adding year', year, 'to database in', time.time() - start, 'seconds')\n",
    "print('COMPLETE in', time.time() - begin_everything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f54da",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_names_for_files = ['Boston_MA', 'Providence_RI', 'Kingston_RI', 'Westerly_RI', 'Mystic_CT',\n",
    "                            'New_London_CT', 'Old_Saybrook_CT', 'New_Haven_CT', 'Bridgeport_CT', \n",
    "                            'Stamford_CT', 'New_Rochelle_NY', 'Manhattan_NY', 'Newark_NJ', 'Iselin_NJ', \n",
    "                            'Trenton_NJ', 'Philadelphia_PA', 'Wilmington_DE','Aberdeen_MD', 'Baltimore_MD',\n",
    "                            'Baltimore_BWI_Airport_MD', 'New_Carrollton_MD', 'Washington_DC']\n",
    "\n",
    "years = [2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021]\n",
    "\n",
    "# Insert all weather data into the weather data table\n",
    "begin_everything = time.time()\n",
    "for location in location_names_for_files:\n",
    "    start = time.time()\n",
    "    for year in years:\n",
    "        weather_csv = './data/weather/{}_weather_subset_{}.csv'.format(location, year)\n",
    "        update_table(conn, insert_into_weather, weather_csv)\n",
    "    print('Finished adding location', location, 'to database in', time.time() - start, 'seconds')\n",
    "print(\"COMPLETE in\", time.time() - begin_everything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18030011",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dates_trains = \"\"\"\n",
    "                      DROP TABLE IF EXISTS dates_trains CASCADE;\n",
    "                      CREATE TABLE dates_trains AS SELECT DISTINCT\n",
    "                          origin_date,\n",
    "                          train_num\n",
    "                      FROM\n",
    "                          stops\n",
    "                      GROUP BY\n",
    "                          origin_date,\n",
    "                          train_num;\n",
    "\n",
    "                      ALTER TABLE dates_trains\n",
    "                          ADD COLUMN trip_id SERIAL PRIMARY KEY;\n",
    "                      \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10c0ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_command(conn, create_dates_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79ed8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_data = \"\"\"\n",
    "            CREATE TABLE stops_joined AS\n",
    "            SELECT\n",
    "                *\n",
    "            FROM\n",
    "                stops s\n",
    "                INNER JOIN (\n",
    "                    SELECT\n",
    "                        station_code AS si_station_code,\n",
    "                        amtrak_station_name,\n",
    "                        crew_change,\n",
    "                        weather_location_name,\n",
    "                        longitude,\n",
    "                        latitude,\n",
    "                        nb_next_station,\n",
    "                        sb_next_station,\n",
    "                        nb_mile,\n",
    "                        sb_mile,\n",
    "                        nb_stop_num,\n",
    "                        sb_stop_num,\n",
    "                        nb_miles_to_next,\n",
    "                        sb_miles_to_next\n",
    "                    FROM\n",
    "                        station_info) si ON s.station_code = si.si_station_code\n",
    "                INNER JOIN weather_hourly wh ON wh.location = si.weather_location_name\n",
    "                    AND DATE_TRUNC('hour', s.full_act_arr_dep_datetime) = wh.obs_datetime\n",
    "            ORDER BY\n",
    "                s.full_sched_arr_dep_datetime;\n",
    "            \"\"\"\n",
    "\n",
    "alter_joined_table = \"\"\"\n",
    "                      ALTER TABLE stops_joined\n",
    "                          DROP COLUMN location,\n",
    "                          DROP COLUMN obs_datetime,\n",
    "                          DROP COLUMN weather_id,\n",
    "                          DROP COLUMN weather_location_name,\n",
    "                          DROP COLUMN longitude,\n",
    "                          DROP COLUMN latitude;\n",
    "                     \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_command(conn, join_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a68a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_command(conn, alter_joined_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b870df",
   "metadata": {},
   "source": [
    "### Remove duplicate rows\n",
    "* There are 393 duplicate entries which somehow ended up in the dataset, as determined by the unique tuples (`origin_date`, `train_num`, `station_code`, `arrival_or_departure`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d2e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_duplicates = \"\"\"\n",
    "                    DELETE \n",
    "                    FROM stops_joined\n",
    "                    WHERE stops_joined.stop_id IN \n",
    "                    (\n",
    "                        SELECT sj_stop_id\n",
    "                        FROM(\n",
    "                            SELECT \n",
    "                                *, \n",
    "                                sj.stop_id AS sj_stop_id,\n",
    "                                row_number() OVER (PARTITION BY origin_date, train_num, station_code, arrival_or_departure ORDER BY stop_id) \n",
    "                            FROM stops_joined sj\n",
    "                        ) s\n",
    "                        WHERE row_number >= 2\n",
    "                    );\n",
    "                    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c5d937",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_command(conn, remove_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b8d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_trip_ids_col = \"\"\"\n",
    "                   ALTER TABLE\n",
    "                   ADD COLUMN trip_id integer;\n",
    "                   \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2983fb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_function_get_stop_ids = \"\"\"\n",
    "                               CREATE FUNCTION get_all_stop_ids (origin_date date, train_num text, OUT stop_id int, OUT station_code text)\n",
    "                                    RETURNS SETOF record\n",
    "                                    AS $$\n",
    "                                        SELECT\n",
    "                                            stop_id,\n",
    "                                            station_code\n",
    "                                        FROM\n",
    "                                            stops_joined\n",
    "                                        WHERE\n",
    "                                            origin_date = $1\n",
    "                                        AND train_num = $2;\n",
    "\n",
    "                                $$\n",
    "                                LANGUAGE SQL;\n",
    "                               \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_command(conn, add_trip_ids_col)\n",
    "execute_command(conn, create_function_get_stop_idss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645274ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_cloud_level = \"\"\"ALTER TABLE stops_joined ADD COLUMN cloud_level integer;\"\"\"\n",
    "\n",
    "\n",
    "set_cloud_level = \"\"\"UPDATE\n",
    "                        stops_joined\n",
    "                     SET\n",
    "                        cloud_level = (\n",
    "                            CASE WHEN cloud_cover < 10 THEN\n",
    "                                0\n",
    "                            WHEN cloud_cover BETWEEN 10\n",
    "                                AND 34.999 THEN\n",
    "                                1\n",
    "                            WHEN cloud_cover BETWEEN 35\n",
    "                                AND 74.999 THEN\n",
    "                                2\n",
    "                            WHEN cloud_cover >= 75 THEN\n",
    "                                3\n",
    "                            END)\n",
    "                     WHERE\n",
    "                        cloud_cover IS NOT NULL;\n",
    "                    \"\"\"\n",
    "    \n",
    "execute_command(conn, add_cloud_level)\n",
    "execute_command(conn, set_cloud_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c125de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_below_freezing = \"\"\"\n",
    "                     ALTER TABLE stops_joined\n",
    "                     ADD COLUMN below_freezing boolean;\n",
    "                     \"\"\"\n",
    "set_below_freezing = \"\"\"\n",
    "                     UPDATE\n",
    "                        stops_joined\n",
    "                     SET\n",
    "                        below_freezing = (\n",
    "                            CASE WHEN temperature >= 32 THEN\n",
    "                                '0'\n",
    "                            ELSE\n",
    "                                '1'\n",
    "                            END\n",
    "                        WHERE\n",
    "                            temperature IS NOT NULL;\n",
    "                    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c10d11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_command(conn, add_below_freezing\n",
    "execute_command(conn, set_below_freezing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797aced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_above_temp_thresh = \"\"\"ALTER TABLE stops_joined ADD COLUMN above_temp_thresh boolean;\"\"\"\n",
    "set_above_temp_thresh = \"\"\"\n",
    "                        UPDATE\n",
    "                            stops_joined\n",
    "                        SET\n",
    "                            above_temp_thresh = (\n",
    "                                CASE WHEN temperature < 90 THEN\n",
    "                                    '0'\n",
    "                                ELSE\n",
    "                                    '1'\n",
    "                                END) \n",
    "                        WHERE\n",
    "                            temperature IS NOT NULL;\n",
    "                        \"\"\"\n",
    "\n",
    "execute_command(conn, add_above_temp_thresh)\n",
    "execute_command(conn, set_above_temp_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bb3247",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_precip_flag = \"\"\"ALTER TABLE stops_joined ADD COLUMN precip_exists boolean;\"\"\"\n",
    "set_precip_flag = \"\"\"UPDATE\n",
    "                        stops_joined\n",
    "                     SET\n",
    "                        weather_cond_exists = (\n",
    "                            CASE WHEN weather_type LIKE '%Snow%' OR weather_type LIKE '%Rain%' THEN\n",
    "                                '1'\n",
    "                            ELSE\n",
    "                                '0'\n",
    "                            END)\n",
    "                     WHERE\n",
    "                        weather_type IS NOT NULL;\n",
    "                    \"\"\"\n",
    "\n",
    "execute_command(conn, add_precip_flag)\n",
    "execute_command(conn, set_precip_flag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce58133",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_precip_level = \"\"\"ALTER TABLE stops_joined ADD COLUMN precip_level integer;\"\"\"\n",
    "\n",
    "set_precip_level = \"\"\"\n",
    "                    UPDATE\n",
    "                        stops_joined\n",
    "                    SET\n",
    "                        precip_level = (\n",
    "                            CASE WHEN precipitation BETWEEN 0.01\n",
    "                                AND 0.09999 THEN\n",
    "                                1\n",
    "                            WHEN precipitation BETWEEN 0.10\n",
    "                                AND 0.24999 THEN\n",
    "                                2\n",
    "                            WHEN precipitation BETWEEN 0.250\n",
    "                                AND 0.40999 THEN\n",
    "                                3\n",
    "                            WHEN precipitation BETWEEN 0.50\n",
    "                                AND 0.74999 THEN\n",
    "                                4\n",
    "                            WHEN precipitation >= 0.75 THEN\n",
    "                                5\n",
    "                            ELSE\n",
    "                                0\n",
    "                            END)\n",
    "                    WHERE\n",
    "                        precipitation IS NOT NULL;\n",
    "                   \"\"\"\n",
    "\n",
    "execute_command(conn, add_precip_level)\n",
    "execute_command(conn, set_precip_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3d1a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_worst_case_precip = \"\"\"ALTER TABLE stops_joined\n",
    "                           ADD COLUMN worst_case_precip integer;\"\"\"\n",
    "\n",
    "set_worst_case_precip = \"\"\"\n",
    "                        UPDATE\n",
    "                            stops_joined\n",
    "                        SET\n",
    "                            worst_case_precip = (\n",
    "                                CASE WHEN weather_type LIKE '%Snow%'\n",
    "                                    AND weather_type LIKE '%Rain%' THEN\n",
    "                                    3\n",
    "                                WHEN weather_type LIKE '%Snow%'\n",
    "                                    AND weather_type NOT LIKE '%Rain%' THEN\n",
    "                                    3\n",
    "                                WHEN weather_type LIKE '%Thunderstorm%'\n",
    "                                    OR weather_type LIKE '%Hail%' THEN\n",
    "                                    3\n",
    "                                WHEN weather_type LIKE '%Rain%'\n",
    "                                    AND weather_type NOT LIKE '%Snow%' THEN\n",
    "                                    2\n",
    "                                WHEN weather_type = '' THEN\n",
    "                                    0\n",
    "                                ELSE\n",
    "                                    1\n",
    "                                END)\n",
    "                        WHERE\n",
    "                            weather_type IS NOT NULL;\n",
    "                        \"\"\"\n",
    "\n",
    "execute_command(conn, add_worst_case_precip)\n",
    "execute_command(conn, set_worst_case_precip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84457332",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
